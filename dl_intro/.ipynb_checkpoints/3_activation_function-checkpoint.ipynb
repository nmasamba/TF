{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='data/simple_net.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform forward propagation for above neural network\n",
    "# Remember: we only supply values for the input layer\n",
    "# Think of each node in the input layer as a feature value for some given data point\n",
    "input_layer = np.array([2, 3])\n",
    "\n",
    "# The neural network is responsible for computing the wights\n",
    "# For this forward propagation example, we'll hard-code them\n",
    "weights = {'input_node_0': np.array([1, 1]),\n",
    "          'input_node_1': np.array([-1, 1]),\n",
    "          'output': np.array([2, -1])}\n",
    "\n",
    "node_0_value = (input_layer * weights['input_node_0']).sum()\n",
    "node_1_value = (input_layer * weights['input_node_1']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pass the node values through an activation function\n",
    "# An activation function enables the model to capture nonlinearities in the data\n",
    "# Common activation functions include tanh and ReLU (Rectified Linear Unit)\n",
    "node_0_output = np.tanh(node_0_value)\n",
    "node_1_output = np.tanh(node_1_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9999092  0.76159416]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Inspect hidden layer output values\n",
    "hidden_layer_values = np.array([node_0_output, node_1_output])\n",
    "print(hidden_layer_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.844948383019356\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Inspect output layer\n",
    "# Notice how outputs have changed significantly from those in the neural net figure above\n",
    "hidden_layer_output = (hidden_layer_values * weights['output']).sum()\n",
    "neural_net_output = np.tanh(hidden_layer_output)\n",
    "print(neural_net_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Also try the ReLU activation function\n",
    "# ReLU takes a scalar as input\n",
    "# Returns the number as output if greater than 0, otherwise returns 0\n",
    "def relu(input):\n",
    "    output = max(0, input)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ReLU(x) = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      0: x \\le 0 \\\\\n",
    "      x: x > 0 \\\\\n",
    "\\end{array} \n",
    "\\right.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_0_relu = relu(node_0_value)\n",
    "node_1_relu = relu(node_1_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 1]\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_relu = np.array([node_0_relu, node_1_relu])\n",
    "print(hidden_layer_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_relu_output = (hidden_layer_relu * weights['output']).sum()\n",
    "neural_net_relu_output = relu(hidden_layer_relu_output)\n",
    "print(neural_net_relu_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rules vs Random (PhD)",
   "language": "python",
   "name": "rules_vs_random"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
