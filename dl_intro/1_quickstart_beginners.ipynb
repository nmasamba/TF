{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 2 Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mnist_db = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the TF pregenarated MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 101 222 159 113 114  12   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  57 163 226 249 252 252 252 253 228  97   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  76 234 252 253 252 252 220 252 253 252 239  66   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 197 252 252 225  99  84  37  84 146 249 252 180  13\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  48 227 252 173   0   0   0   0   0   0 225 252 252 112\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  86 228  47   0   0   0   0   0   0   0 163 253 253 112\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   9  21   0   0   0   0   0   0   0   0  85 252 252 112\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  85 252 252 189\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  13 104 252 252 112\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  79 191 252 252 252 112\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  29 253 255 253 253 253 253\n",
      "   63   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   3 152 253 252 252 252 252\n",
      "  241  24   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  31  56  55  55 155 252\n",
      "  253  59   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  10 177\n",
      "  253 224  53   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  48 140 126   0   0   0   0   0  63\n",
      "  253 252 195   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 226 253  84   0   0   0   0   0   0\n",
      "  192 253 196   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 225 252 234 146  85  57   0   0  48\n",
      "  159 252 195   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  97 208 252 252 253 233 197 197 227\n",
      "  253 252 195   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  19  99 223 237 252 252 252 252\n",
      "  253 226  96   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  50 237 252 252 252\n",
      "  190  12   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[198])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(y_train[198])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalise training data by dividing by largest possible value (255)\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "rows_n_cols = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify-Compile-Fit Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Callback for early stopping monitor\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build a tf.keras.Sequential model by stacking layers\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=rows_n_cols),\n",
    "  tf.keras.layers.Dense(20, activation='relu'),\n",
    "  tf.keras.layers.Dense(20, activation='relu'),\n",
    "  tf.keras.layers.Dense(20, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 16,750\n",
      "Trainable params: 16,750\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Predictions: [[ 0.06695157 -0.25264922  0.10339264  0.16235812 -0.02507077  0.09732696\n",
      "  -0.18154924 -0.17175665  0.02743593  0.29795864]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model returns a vector of log-odds scores, one for each class\n",
    "predictions = model(x_train[:1]).numpy()\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for each class: \n",
      " [[0.10421745 0.07570763 0.1080853  0.11465025 0.09505516 0.10743167\n",
      "  0.08128642 0.08208632 0.10017955 0.13130026]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The tf.nn.softmax function calibrates logits to probabilities for each class\n",
    "print(\"Probabilities for each class: \\n\", tf.nn.softmax(predictions).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define loss function\n",
    "# Sparse Categorical Cross Entropy loss returns a scalar loss for each example\n",
    "loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configure model's optimizer, loss and evaluation metric (among others)\n",
    "# Compile the configured model in the same step\n",
    "adam_opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=adam_opt,\n",
    "              loss=loss_function,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.4669 - accuracy: 0.8651\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3257 - accuracy: 0.9131\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2990 - accuracy: 0.9215\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2825 - accuracy: 0.9265\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2809 - accuracy: 0.9272\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2743 - accuracy: 0.9274\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2611 - accuracy: 0.9318\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2594 - accuracy: 0.9336\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.2594 - accuracy: 0.9315\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2540 - accuracy: 0.9345\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2501 - accuracy: 0.9373\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.2512 - accuracy: 0.9350\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2444 - accuracy: 0.9376s - loss: 0.245\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2331 - accuracy: 0.9401\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.2417 - accuracy: 0.9383\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.2412 - accuracy: 0.9367\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2390 - accuracy: 0.9381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fae6045c250>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fit the model to data\n",
    "# This optimisation step adjusts the model's parameters (weights) and miminimises the loss\n",
    "model.fit(x_train, y_train, epochs=50, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 1s - loss: 0.1345 - accuracy: 0.9362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26292665624087674, 0.9362]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model on a validation/test set\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.32941176 0.7254902  0.62352941 0.59215686 0.23529412 0.14117647\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.87058824 0.99607843 0.99607843 0.99607843 0.99607843 0.94509804\n",
      "  0.77647059 0.77647059 0.77647059 0.77647059 0.77647059 0.77647059\n",
      "  0.77647059 0.77647059 0.66666667 0.20392157 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.2627451  0.44705882 0.28235294 0.44705882 0.63921569 0.89019608\n",
      "  0.99607843 0.88235294 0.99607843 0.99607843 0.99607843 0.98039216\n",
      "  0.89803922 0.99607843 0.99607843 0.54901961 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.06666667\n",
      "  0.25882353 0.05490196 0.2627451  0.2627451  0.2627451  0.23137255\n",
      "  0.08235294 0.9254902  0.99607843 0.41568627 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.3254902  0.99215686 0.81960784 0.07058824 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.08627451\n",
      "  0.91372549 1.         0.3254902  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.50588235\n",
      "  0.99607843 0.93333333 0.17254902 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.23137255 0.97647059\n",
      "  0.99607843 0.24313725 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.52156863 0.99607843\n",
      "  0.73333333 0.01960784 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.03529412 0.80392157 0.97254902\n",
      "  0.22745098 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.49411765 0.99607843 0.71372549\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.29411765 0.98431373 0.94117647 0.22352941\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.0745098  0.86666667 0.99607843 0.65098039 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01176471 0.79607843 0.99607843 0.85882353 0.1372549  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14901961 0.99607843 0.99607843 0.30196078 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.12156863\n",
      "  0.87843137 0.99607843 0.45098039 0.00392157 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.52156863\n",
      "  0.99607843 0.99607843 0.20392157 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.23921569 0.94901961\n",
      "  0.99607843 0.99607843 0.20392157 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.4745098  0.99607843\n",
      "  0.99607843 0.85882353 0.15686275 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.4745098  0.99607843\n",
      "  0.81176471 0.07058824 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test[0] prediction: 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# To calibrate the model and return a probability, wrap the trained model and attach a softmax layer\n",
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "print(\"x_test[0] prediction:\", np.where(probability_model(x_test[:1]) == np.max(probability_model(x_test[:1])))[1][0] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rules vs Random (PhD)",
   "language": "python",
   "name": "rules_vs_random"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
